{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce010664-9ca2-43a0-948f-51afc6af6ce8",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "Before we dive in, we need to set up our environment. This requires installing the Hugging Face Transformers library as well as other dependencies to make it work with paperspace. Normally, you would execute the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a3247-2553-4fd0-a497-95f549d47dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade transformers torch torchvision torchaudio\n",
    "!pip install -q tokenizers==0.14 evaluate\n",
    "!pip install -q bitsandbytes transformers accelerate gradio thread6 sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a7c3a",
   "metadata": {},
   "source": [
    "---\n",
    "### Recap of the Previous Lesson\n",
    "\n",
    "In our previous lesson, we introduced the Hugging Face platform and its high-level component called Pipelines. We explored the zero-shot image classification task and how Hugging Face abstracts the complexities, allowing us to perform such tasks with ease.\n",
    "\n",
    "Today, we'll delve deeper into other practical applications using pipelines, focusing on tasks that are particularly relevant in the business context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57434836",
   "metadata": {},
   "source": [
    "---\n",
    "### Deep Dive: Text Summarization\n",
    "\n",
    "Text summarization models, particularly those used in Hugging Face, are often based on the Transformer architecture. This architecture has shown great success in various NLP tasks due to its self-attention mechanism, which allows the model to weigh the importance of different words relative to a given word.\n",
    "\n",
    "For summarization, models often use a sequence-to-sequence approach. Here's a simplified overview:\n",
    "\n",
    "1. **Encoder**: The input text (long text) is passed through an encoder, which converts the text into a series of vectors that capture its semantic information.\n",
    "2. **Decoder**: These vectors are then passed to a decoder, which generates the summarized text word by word.\n",
    "\n",
    "The self-attention mechanism in the Transformer allows the decoder to focus on different parts of the input text while generating each word of the summary, ensuring that the most relevant information is captured.\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/9PoKellNrBc/maxresdefault.jpg\" width=\"600\" height=\"400\">\n",
    "\n",
    "\n",
    "\n",
    "### Deep Dive: Text Translation\n",
    "\n",
    "Modern translation models also leverage the Transformer architecture. The principle is similar to summarization but adapted for translation between languages:\n",
    "\n",
    "1. **Encoder**: The input text (in the source language) is processed by an encoder, producing a series of vectors that encapsulate its meaning.\n",
    "2. **Decoder**: A decoder then takes these vectors and generates the translation in the target language, word by word.\n",
    "\n",
    "A crucial component here is the attention mechanism. As the decoder generates each word in the target language, the attention mechanism allows it to focus on different parts of the source text. This ensures that the translation is contextually accurate and captures nuances in the source text.\n",
    "\n",
    "\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/enc_dec_simple.png\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa38e8",
   "metadata": {},
   "source": [
    "---\n",
    "### Text Summarization with Pipelines\n",
    "\n",
    "Text summarization is the process of shortening long pieces of text into a concise summary that retains the most important information. In business, this can be incredibly useful for quickly understanding long reports, articles, or documents.\n",
    "\n",
    "Let's see how we can use the Hugging Face pipeline for this task.\n",
    "- ignore the warning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea485e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Use the summarizer on a long piece of text (this is just an example; we'll use a dummy text here)\n",
    "long_text = \"\"\"The Mercer survey was conducted between July 31 and August 11, so the results are just an early look at what employers are thinking as they plan for 2024. \n",
    "Compensation budgets for next year won’t be finalized until December or even January in some instances. And a lot can change between now and then. The expected pay increases \n",
    "for next year reflect “the ongoing tightness of the labor market and low levels of unemployment. However, if the labor market continues to stabilize and inflation cools further as \n",
    "we move towards the end of the year, compensation pressures are likely to continue to decline,” said Lauren Mason, a senior principal in Mercer’s career practice.\"\"\"\n",
    "\n",
    "summary = summarizer(long_text, max_length=50, min_length=25, do_sample=False)\n",
    "print(\"Model output:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b71878",
   "metadata": {},
   "source": [
    "---\n",
    "### Text Translation with Pipelines\n",
    "\n",
    "In the context of global business, the ability to translate content into different languages is invaluable. Whether it's for communicating with international partners, translating product information, or understanding foreign market reports, translation plays a key role.\n",
    "\n",
    "Let's explore how the translation pipeline works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the translation pipeline (translating from English to Spanish in this example)\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "\n",
    "# Translate a sample sentence\n",
    "text_to_translate = \"I am a student at Fresno state University\"\n",
    "translated_text = translator(text_to_translate)\n",
    "print(translated_text[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3d3be",
   "metadata": {},
   "source": [
    "---\n",
    "### Customizing Pipeline Outputs\n",
    "\n",
    "Pipelines in Hugging Face are highly customizable. By tweaking various parameters, we can influence the output. For instance, in text summarization, you might want a shorter or longer summary. By adjusting the `max_length` and `min_length` parameters, you can control the length of the generated summary.\n",
    "\n",
    "Let's see how this works in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2950dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize a text with different lengths\n",
    "long_text = \"\"\"In that case, employers could further trim their planned pay increases. \n",
    "Or they could decide to further boost raises and increase promotions if conditions warrant — \n",
    "as they did this year, when merit increase budgets were set for a 3.8% boost but employers ended \n",
    "up raising base salary levels for employees who remained in their roles by an average of 5.6% instead. \n",
    "“This is a result of off-cycle pay increases, which 59% of employers reported providing in 2023. The top \n",
    "reasons cited for off-cycle increases were to address retention concerns, counteroffers, market adjustments \n",
    "and internal equity,” Mason said. \"\"\"\n",
    "\n",
    "short_summary = summarizer(long_text, max_length=30, min_length=10, do_sample=False)\n",
    "long_summary = summarizer(long_text, max_length=100, min_length=50, do_sample=False)\n",
    "\n",
    "print(\"Short Summary:\", short_summary[0]['summary_text'])\n",
    "print(\"Long Summary:\", long_summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd78c8",
   "metadata": {},
   "source": [
    "---\n",
    "### Understanding Model Limitations\n",
    "\n",
    "While models like those in the Hugging Face library are incredibly powerful, they're not infallible. It's crucial to understand their limitations, especially in a business context where decisions based on model outputs can have real-world consequences.\n",
    "\n",
    "1. **Data Bias**: If a model is trained on biased data, its outputs will reflect that bias. This can lead to incorrect or unfair decisions.\n",
    "2. **Overfitting**: If a model is trained too closely on its training data, it might perform poorly on new, unseen data.\n",
    "3. **Complexity**: Deep learning models, especially transformers, have millions of parameters. While this makes them powerful, it can also make them prone to \"memorizing\" rather than \"learning\" from data.\n",
    "4. **Resource Intensive**: Transformers are resource-intensive, which can be a concern when deploying them in real-world applications.\n",
    "\n",
    "In summary, always evaluate model outputs critically and in the context of the specific business problem you're addressing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f25bbf",
   "metadata": {},
   "source": [
    "---\n",
    "### Practical Exercise\n",
    "\n",
    "Now, it's your turn! Here's a business-related text:\n",
    "\n",
    "> \"Global sales have increased by 15% in the last quarter, with particularly strong performance in the Asia-Pacific region. New product launches have been well-received, and marketing campaigns in Europe are showing promise. However, there are concerns about supply chain disruptions in North America.\"\n",
    "\n",
    "1. Generate a concise summary of the text.\n",
    "2. Translate the summary into French.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094cc60-996a-48fa-88ba-dddd26ed53a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
